{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f780e-ea1d-4689-8300-278858e39fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698706fa-7d9f-483b-93ae-a109b60a68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance the APP VARIABLES\n",
    "SYSTEM_PROMPT_PATH = \"../system_prompt.txt\"\n",
    "CHROMA_DB = \"../chromadb/persistent_db/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144b781-f109-429c-9246-046f29b00b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB)\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"cv_doc\",\n",
    "    metadata = {\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b2f68-6053-4bf6-ab32-63f4c659bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "\n",
    "    # Inits the basic atributes of the chatbot\n",
    "    def __init__(self, system_prompt_path: str):\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        self.system_prompt = self.read_doc(system_prompt_path) # init system_prompt\n",
    "        self.context = self.system_prompt #init context\n",
    "        self.documents = \"\" #init documents where data is extracted\n",
    "        self.messages = [{\"role\": \"system\",\"content\" : self.context}] #init of messages of the chat\n",
    "        self.client = Groq(api_key= self.api_key)\n",
    "\n",
    "  \n",
    "    # Gets the user input message\n",
    "    def get_user_message(self):\n",
    "        return input(\"Escribe tu mensaje: \")\n",
    "    \n",
    "    # Appends user message in the message history\n",
    "    def add_user_message(self, message: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # Add the role assistant to the message pool list.\n",
    "    def add_assistant_message(self, message: str):\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "    # Reads the documents from the system\n",
    "    def read_doc(self, path: str) -> str:\n",
    "        with open(path, 'r') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # Generates the model, params, and options    \n",
    "    def get_completion(self):\n",
    "        return self.client.chat.completions.create( \n",
    "            model=\"llama-3.1-8b-instant\", \n",
    "            messages=self.messages, \n",
    "            temperature=1, \n",
    "            max_tokens=1024, \n",
    "            top_p=1, \n",
    "            stream=True,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "    # Gets the user message > gets the context documents > append the user message to chat > updates system content\n",
    "    def handle_user_query(self, user_message : str) :\n",
    "        self.documents = self.get_context_query(user_message) # gets the new context\n",
    "        self.context = self.system_prompt + self.documents # updates the new context for the model\n",
    "        self.add_user_message(user_message) # adds the user message to the chat\n",
    "        self.messages[0]['content'] = self.context # update the context message with the new context\n",
    "    \n",
    "    #Gets the embeddings context from user message\n",
    "    def get_context_query(self, user_message : str) -> str :\n",
    "        query_results = collection.query(\n",
    "        query_texts = user_message,\n",
    "        n_results= 3\n",
    "        )\n",
    "        context_entries = []  # Lista para almacenar las entradas del contexto\n",
    "\n",
    "        # Recorre los documentos y metadatos obtenidos\n",
    "        for doc, metadata in zip(query_results['documents'][0], query_results['metadatas'][0]):\n",
    "            # Formatear el texto del documento y los metadatos\n",
    "            context_entry = f'{{\"data\": \"{doc}\", \"url_source\": \"{metadata.get(\"document\", \"N/A\")}\"}}'\n",
    "            context_entries.append(context_entry)\n",
    "\n",
    "        # Devuelve las entradas de contexto como una cadena\n",
    "        print(context_entries)\n",
    "        return str(context_entries)\n",
    "        \n",
    "    # Generates a iteration on the chat: add user and assistant messages to the history.\n",
    "    def chat_iteration(self, user_message : str):\n",
    "        self.handle_user_query(user_message)\n",
    "        \n",
    "        completion = self.get_completion()\n",
    "        assistant_response = \"\"\n",
    "        for chunk in completion:\n",
    "            response_part = chunk.choices[0].delta.content or \"\"\n",
    "            print(response_part, end=\"\")\n",
    "            assistant_response += response_part\n",
    "        self.add_assistant_message(assistant_response)\n",
    "\n",
    "    # Generates the chat funcion that allow users send multiple messages on a conversation\n",
    "    def chat(self):\n",
    "        while True:\n",
    "            user_message = self.get_user_message()\n",
    "            if user_message.strip().lower() == \"/exit\" :\n",
    "                print(\"Hasta luego!\")\n",
    "                break\n",
    "            self.chat_iteration(user_message) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e09a30-cc69-433d-9574-fb819052b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(SYSTEM_PROMPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc71f5b-60bc-48d2-a760-265801a0a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
